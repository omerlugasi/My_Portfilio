{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Part A**\n"
      ],
      "metadata": {
        "id": "oYn4BCHWGQoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1.**"
      ],
      "metadata": {
        "id": "8FWrD-h8Gae9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MRJob library\n",
        "!pip install MRJob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfVvSjbjOipA",
        "outputId": "fa975b29-4d3f-4d9f-8151-02a96cf479d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: MRJob in /usr/local/lib/python3.11/dist-packages (0.7.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from MRJob) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Save the script to a file for MRJob to run\n",
        "%%file hw1_mrA1_212536924_322836180.py\n",
        "\n",
        "# This MRJob script processes TV show data to find shows that aired between 13:30 and 16:29,\n",
        "# meet genre and title conditions, and counts the number of unique air dates for each title.\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "from datetime import time\n",
        "import re\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class MRBigBrotherPrograms(MRJob):\n",
        "\n",
        "  # Constants:\n",
        "  START_TIME = time(13, 30, 0)\n",
        "  END_TIME = time(16, 29, 59)\n",
        "  GOOD_GENRES = ['Reality', 'Community', 'Adventure', 'Animated']\n",
        "  GOOD_LETTERS = ['p', 'w', 'm']\n",
        "  BAD_LETTERS = ['a', 'b']\n",
        "\n",
        "  SHOW_TITLE_INDEX = 0\n",
        "  GENRE_INDEX = 2\n",
        "  AIR_DATE_INDEX = 3\n",
        "  AIR_TIME_INDEX = 4\n",
        "\n",
        "\n",
        "  def steps(self):\n",
        "\n",
        "    return [\n",
        "            # Step 1: Fulfill conditions 2,3,4\n",
        "            MRStep(mapper=self.mapper_conditions_234),\n",
        "\n",
        "            # Step 2: Fulfill condition 1 and format result\n",
        "            MRStep(mapper=self.mapper_filter_irrelevant_dates,\n",
        "                   reducer=self.reducer_unique_dates)]\n",
        "\n",
        "\n",
        "\n",
        "  def mapper_filter_irrelevant_dates(self, title, values):\n",
        "    # Filter dates where the airing time is not between 13:30 and 16:29\n",
        "\n",
        "    date = values[0]\n",
        "    air_time_raw = int(values[1])\n",
        "    good_genre_list = values[2]\n",
        "    genre_count = values[3]\n",
        "\n",
        "    air_time = time(air_time_raw // 10000, (air_time_raw % 10000) // 100, air_time_raw % 100)\n",
        "\n",
        "    if self.START_TIME <= air_time <= self.END_TIME:\n",
        "      # Set title as key so we can count dates after\n",
        "      yield title, (date, good_genre_list, genre_count)\n",
        "\n",
        "\n",
        "\n",
        "  def mapper_conditions_234(self, _, line):\n",
        "    # Filters rows based on:\n",
        "    # - Condition 2: Genre contains one of GOOD_GENRES\n",
        "    # - Condition 3: Title has at least two of GOOD_LETTERS\n",
        "    # - Condition 4: Title has none of BAD_LETTERS\n",
        "\n",
        "    for row in csv.reader(StringIO(line)):\n",
        "      # The above line parses the CSV file into a list of rows and then iterates\n",
        "\n",
        "      # Skip header row\n",
        "      if row[self.AIR_TIME_INDEX] == \"air_time\":\n",
        "        continue\n",
        "\n",
        "      title = row[self.SHOW_TITLE_INDEX]\n",
        "      genre_list = row[self.GENRE_INDEX]\n",
        "\n",
        "      good_genre_list = [title]\n",
        "\n",
        "      # Condition 2:\n",
        "      condition_two = False\n",
        "      for genre in self.GOOD_GENRES:\n",
        "          if genre in genre_list:\n",
        "            good_genre_list.append(genre)\n",
        "            condition_two = True\n",
        "\n",
        "      # Condition 3:\n",
        "      counter = 0\n",
        "      for letter in self.GOOD_LETTERS:\n",
        "        if letter in title.lower():\n",
        "          counter += 1\n",
        "\n",
        "      condition_three = counter >= 2\n",
        "\n",
        "      # Condition 4:\n",
        "      condition_four = True\n",
        "      for letter in self.BAD_LETTERS:\n",
        "        if letter in title.lower():\n",
        "          condition_four = False\n",
        "\n",
        "      total_genre_count = len(genre_list.split(','))\n",
        "\n",
        "      if condition_two and condition_three and condition_four:\n",
        "        yield title, (row[self.AIR_DATE_INDEX], row[self.AIR_TIME_INDEX], good_genre_list, total_genre_count)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def reducer_unique_dates(self, title, values):\n",
        "    # Count unique dates\n",
        "    dates = set()\n",
        "\n",
        "\n",
        "    for air_date, good_genre_list, genre_count in values:\n",
        "      dates.add(air_date)\n",
        "      genre_list = good_genre_list\n",
        "      num_of_genres = genre_count\n",
        "\n",
        "    yield genre_list, (len(dates), genre_count)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  MRBigBrotherPrograms.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NI-1Ak52aGU",
        "outputId": "65311cb9-5cd1-4978-bf3d-20faf3248aba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hw1_mrA1_212536924_322836180.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run and save py file\n",
        "!python hw1_mrA1_212536924_322836180.py \"440k_data.csv\" -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evZl_EShObLC",
        "outputId": "7d99e1eb-6ed4-4aa0-c47b-0ecf2581e599"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"600 Pound Mom\", \"Reality\"]\t[1, 3]\n",
            "[\"Computerwise\", \"Community\"]\t[2, 1]\n",
            "[\"El Show de Tom y Jerry\", \"Animated\"]\t[1, 3]\n",
            "[\"Empowered: Keys to Unlocking\", \"Community\"]\t[3, 2]\n",
            "[\"Extreme Couponing\", \"Reality\"]\t[4, 1]\n",
            "[\"Jiggijump\", \"Adventure\"]\t[20, 3]\n",
            "[\"KUOW's Week In Review Summer Tour\", \"Community\"]\t[1, 1]\n",
            "[\"Lord of the Rings: Fellowship of Ring\", \"Adventure\"]\t[1, 2]\n",
            "[\"Love & Hip Hop: Hollywood\", \"Reality\"]\t[4, 1]\n",
            "[\"Missouri Viewpoints\", \"Community\"]\t[1, 1]\n",
            "[\"My Time With Jesus\", \"Animated\"]\t[3, 2]\n",
            "[\"New Mexico True TV\", \"Community\"]\t[1, 1]\n",
            "[\"Pok & Mok\", \"Animated\"]\t[1, 3]\n",
            "[\"Pok\\u00e9mon 4Ever\", \"Adventure\", \"Animated\"]\t[1, 3]\n",
            "[\"Pok\\u00e9mon: XY\", \"Animated\"]\t[16, 4]\n",
            "[\"Pompeii\", \"Adventure\"]\t[6, 3]\n",
            "[\"Semper Ride\", \"Community\"]\t[1, 1]\n",
            "[\"Shipwrecked\", \"Adventure\"]\t[1, 1]\n",
            "[\"Super Why!\", \"Animated\"]\t[119, 3]\n",
            "[\"Super Wings\", \"Adventure\", \"Animated\"]\t[14, 4]\n",
            "[\"Swim Week\", \"Community\"]\t[4, 3]\n",
            "[\"The Powerpuff Girls\", \"Adventure\", \"Animated\"]\t[365, 4]\n",
            "[\"The Sylvester & Tweety Mysteries\", \"Animated\"]\t[6, 3]\n",
            "[\"The Wonder Pets!\", \"Animated\"]\t[16, 4]\n",
            "[\"Top 20 Most Shocking\", \"Reality\"]\t[3, 2]\n",
            "[\"Two More Eggs\", \"Animated\"]\t[8, 3]\n",
            "[\"Who Rocks New Mexico\", \"Community\"]\t[1, 1]\n",
            "[\"Who's on Top?\", \"Reality\"]\t[2, 1]\n",
            "[\"Wild Spirits\", \"Adventure\"]\t[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2.**"
      ],
      "metadata": {
        "id": "1N0QVn3yGXGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MRJob library\n",
        "!pip install MRJob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8379ef-1929-470b-881f-a888c41aebfa",
        "id": "Jx-u-MOsGv-R"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: MRJob in /usr/local/lib/python3.11/dist-packages (0.7.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from MRJob) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save MRJob part A2 script to file\n",
        "%%file hw1_mrA2_212536924_322836180.py\n",
        "\n",
        "# Extends part A1 by adding a third step:\n",
        "# After filtering and counting unique air dates, it selects the best program\n",
        "# based on a custom score: (number of unique air dates + number of genres).\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "from datetime import time\n",
        "import re\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class MRBigBrotherPrograms(MRJob):\n",
        "\n",
        "  # Constants:\n",
        "  START_TIME = time(13, 30, 0)\n",
        "  END_TIME = time(16, 29, 59)\n",
        "  GOOD_GENRES = ['Reality', 'Community', 'Adventure', 'Animated']\n",
        "  GOOD_LETTERS = ['p', 'w', 'm']\n",
        "  BAD_LETTERS = ['a', 'b']\n",
        "\n",
        "  SHOW_TITLE_INDEX = 0\n",
        "  GENRE_INDEX = 2\n",
        "  AIR_DATE_INDEX = 3\n",
        "  AIR_TIME_INDEX = 4\n",
        "\n",
        "\n",
        "  def steps(self):\n",
        "\n",
        "    return [\n",
        "            # Step 1: Fulfill conditions 2,3,4\n",
        "            MRStep(mapper=self.mapper_conditions_234),\n",
        "\n",
        "            # Step 2: Fulfill condition 1 and format result\n",
        "            MRStep(mapper=self.mapper_filter_irrelevant_dates,\n",
        "                   reducer=self.reducer_unique_dates),\n",
        "            MRStep(mapper=self.mapper_title_value,\n",
        "                   reducer=self.reducer_best_program)]\n",
        "\n",
        "\n",
        "\n",
        "  def mapper_filter_irrelevant_dates(self, title, values):\n",
        "    # Filter dates where the airing time is not between 13:30 and 16:29\n",
        "\n",
        "    date = values[0]\n",
        "    air_time_raw = int(values[1])\n",
        "    good_genre_list = values[2]\n",
        "    genre_count = values[3]\n",
        "\n",
        "    air_time = time(air_time_raw // 10000, (air_time_raw % 10000) // 100, air_time_raw % 100)\n",
        "\n",
        "    if self.START_TIME <= air_time <= self.END_TIME:\n",
        "      # Set title as key so we can count dates after\n",
        "      yield title, (date, good_genre_list, genre_count)\n",
        "\n",
        "\n",
        "\n",
        "  def mapper_conditions_234(self, _, line):\n",
        "    # Filter rows who don't satisfy conditions 2, 3 or 4\n",
        "\n",
        "    for row in csv.reader(StringIO(line)):\n",
        "      # The above line parses the CSV file into a list of rows and then iterates\n",
        "\n",
        "      # Skip header row\n",
        "      if row[self.AIR_TIME_INDEX] == \"air_time\":\n",
        "        continue\n",
        "\n",
        "      title = row[self.SHOW_TITLE_INDEX]\n",
        "      genre_list = row[self.GENRE_INDEX]\n",
        "\n",
        "      good_genre_list = [title]\n",
        "\n",
        "      # Condition 2:\n",
        "      condition_two = False\n",
        "      for genre in self.GOOD_GENRES:\n",
        "          if genre in genre_list:\n",
        "            good_genre_list.append(genre)\n",
        "            condition_two = True\n",
        "\n",
        "      # Condition 3:\n",
        "      counter = 0\n",
        "      for letter in self.GOOD_LETTERS:\n",
        "        if letter in title.lower():\n",
        "          counter += 1\n",
        "\n",
        "      condition_three = counter >= 2\n",
        "\n",
        "      # Condition 4:\n",
        "      condition_four = True\n",
        "      for letter in self.BAD_LETTERS:\n",
        "        if letter in title.lower():\n",
        "          condition_four = False\n",
        "\n",
        "      total_genre_count = len(genre_list.split(','))\n",
        "\n",
        "      if condition_two and condition_three and condition_four:\n",
        "        yield title, (row[self.AIR_DATE_INDEX], row[self.AIR_TIME_INDEX], good_genre_list, total_genre_count)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def reducer_unique_dates(self, title, values):\n",
        "    # Count unique dates\n",
        "    dates = set()\n",
        "\n",
        "\n",
        "    for air_date, good_genre_list, genre_count in values:\n",
        "      dates.add(air_date)\n",
        "      genre_list = good_genre_list\n",
        "      num_of_genres = genre_count\n",
        "\n",
        "    yield genre_list, (len(dates), genre_count)\n",
        "\n",
        "\n",
        "  def mapper_title_value(self, key, value):\n",
        "    yield None, (key[0], value[0]+value[1])\n",
        "\n",
        "\n",
        "  def reducer_best_program(self, _, title_value_pairs):\n",
        "    yield max(title_value_pairs, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  MRBigBrotherPrograms.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN8UlyI-GxT5",
        "outputId": "5004fa01-b47d-43cc-e376-912a44df15db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hw1_mrA2_212536924_322836180.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run and save py file\n",
        "!python hw1_mrA1_212536924_322836180.py \"440k_data.csv\" -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVYcll_RG4P7",
        "outputId": "cc3f072b-1ef6-4bac-940e-f380ce5355ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"600 Pound Mom\", \"Reality\"]\t[1, 3]\n",
            "[\"Computerwise\", \"Community\"]\t[2, 1]\n",
            "[\"El Show de Tom y Jerry\", \"Animated\"]\t[1, 3]\n",
            "[\"Empowered: Keys to Unlocking\", \"Community\"]\t[3, 2]\n",
            "[\"Extreme Couponing\", \"Reality\"]\t[4, 1]\n",
            "[\"Jiggijump\", \"Adventure\"]\t[20, 3]\n",
            "[\"KUOW's Week In Review Summer Tour\", \"Community\"]\t[1, 1]\n",
            "[\"Lord of the Rings: Fellowship of Ring\", \"Adventure\"]\t[1, 2]\n",
            "[\"Love & Hip Hop: Hollywood\", \"Reality\"]\t[4, 1]\n",
            "[\"Missouri Viewpoints\", \"Community\"]\t[1, 1]\n",
            "[\"My Time With Jesus\", \"Animated\"]\t[3, 2]\n",
            "[\"New Mexico True TV\", \"Community\"]\t[1, 1]\n",
            "[\"Pok & Mok\", \"Animated\"]\t[1, 3]\n",
            "[\"Pok\\u00e9mon 4Ever\", \"Adventure\", \"Animated\"]\t[1, 3]\n",
            "[\"Pok\\u00e9mon: XY\", \"Animated\"]\t[16, 4]\n",
            "[\"Pompeii\", \"Adventure\"]\t[6, 3]\n",
            "[\"Semper Ride\", \"Community\"]\t[1, 1]\n",
            "[\"Shipwrecked\", \"Adventure\"]\t[1, 1]\n",
            "[\"Super Why!\", \"Animated\"]\t[119, 3]\n",
            "[\"Super Wings\", \"Adventure\", \"Animated\"]\t[14, 4]\n",
            "[\"Swim Week\", \"Community\"]\t[4, 3]\n",
            "[\"The Powerpuff Girls\", \"Adventure\", \"Animated\"]\t[365, 4]\n",
            "[\"The Sylvester & Tweety Mysteries\", \"Animated\"]\t[6, 3]\n",
            "[\"The Wonder Pets!\", \"Animated\"]\t[16, 4]\n",
            "[\"Top 20 Most Shocking\", \"Reality\"]\t[3, 2]\n",
            "[\"Two More Eggs\", \"Animated\"]\t[8, 3]\n",
            "[\"Who Rocks New Mexico\", \"Community\"]\t[1, 1]\n",
            "[\"Who's on Top?\", \"Reality\"]\t[2, 1]\n",
            "[\"Wild Spirits\", \"Adventure\"]\t[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part B**"
      ],
      "metadata": {
        "id": "lrJ97kVOkG_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules for date handling, CSV processing, and Spark DataFrame operations\n",
        "from datetime import datetime, time, timedelta\n",
        "\n",
        "import csv\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import (\n",
        "    col, floor, lower, split, size, array_contains,\n",
        "    to_date, expr, when, sum as _sum\n",
        ")"
      ],
      "metadata": {
        "id": "STC-QNErlkML"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "64bdffb1-2078-4ebb-88d9-d743b8f2225b"
      },
      "outputs": [],
      "source": [
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName('HW1').getOrCreate() #Create SparkSession\n",
        "sc = spark.sparkContext\n",
        "# keep only important logs\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to read a Big Brother CSV file into a Spark DataFrame using a predefined schema.\n",
        "\n",
        "def read_from_file(filename):\n",
        "  # Read from big brother csv\n",
        "\n",
        "  schema = StructType([\n",
        "    StructField(\"title\", StringType(), True),\n",
        "    StructField(\"prog_code\", StringType(), True),\n",
        "    StructField(\"genre\", StringType(), True),\n",
        "    StructField(\"air_date\", StringType(), True),\n",
        "    StructField(\"air_time\", IntegerType(), True),\n",
        "    StructField(\"Duration\", StringType(), True)])\n",
        "\n",
        "  df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema) \\\n",
        "  .load(filename)\n",
        "  return df"
      ],
      "metadata": {
        "id": "b5FB1mJHZ3LX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filters out unwanted programs and scores the rest based on genre, duration, and title,\n",
        "# returning a ranked list by total score.\n",
        "\n",
        "# Filter out programs with at least one airing on Thursday between 13:30–15:30\n",
        "def filter_thursday(df):\n",
        "    # Parse air_date string to DateType to extract weekday\n",
        "    df = df.withColumn(\"air_date_parsed\", to_date(col(\"air_date\"), \"yyyyMMdd\"))\n",
        "\n",
        "    # Filter for Thursday (Spark: 1=Sunday, ..., 5=Thursday)\n",
        "    df_thurs = df.filter(expr(\"EXTRACT(DAYOFWEEK FROM air_date_parsed) = 5\"))\n",
        "\n",
        "    # Compute start time in minutes since midnight\n",
        "    df_thurs = df_thurs.withColumn(\"start_hour\", floor(col(\"air_time\") / 10000)) \\\n",
        "                       .withColumn(\"start_minute\", floor((col(\"air_time\") % 10000) / 100)) \\\n",
        "                       .withColumn(\"start_in_minutes\", col(\"start_hour\") * 60 + col(\"start_minute\"))\n",
        "\n",
        "    # Compute end time by adding duration\n",
        "    df_thurs = df_thurs.withColumn(\"end_in_minutes\", col(\"start_in_minutes\") + col(\"Duration\"))\n",
        "\n",
        "    # Define time window in minutes (13:30 to 15:30)\n",
        "    window_start = 13 * 60 + 30\n",
        "    window_end = 15 * 60 + 30\n",
        "\n",
        "    # Find shows that overlap with the time window\n",
        "    overlap_condition = (col(\"start_in_minutes\") <= window_end) & \\\n",
        "                        (col(\"end_in_minutes\") >= window_start)\n",
        "\n",
        "    df_overlap = df_thurs.filter(overlap_condition)\n",
        "\n",
        "    # Exclude shows (by title) that had any overlapping airing on Thursday\n",
        "    titles_to_exclude = df_overlap.select(\"title\").distinct()\n",
        "    df_filtered = df.join(titles_to_exclude, on=\"title\", how=\"left_anti\")\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "# Filter out programs whose title contains certain keywords\n",
        "def filter_names(df):\n",
        "    keywords = ['friends', 'bang', 'breaking', 'montana', 'doctor', 'fox', 'news']\n",
        "\n",
        "    # Convert titles to lowercase for case-insensitive matching\n",
        "    df = df.withColumn(\"title_lower\", lower(col(\"title\")))\n",
        "\n",
        "    # Build exclusion condition using OR logic\n",
        "    exclude_condition = None\n",
        "    for kw in keywords:\n",
        "        condition = col(\"title_lower\").contains(kw)\n",
        "        exclude_condition = condition if exclude_condition is None else (exclude_condition | condition)\n",
        "\n",
        "    # Filter out titles matching any keyword\n",
        "    df = df.filter(~exclude_condition).drop(\"title_lower\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Wrapper function to apply all filtering steps\n",
        "def filter_df(df):\n",
        "    df = filter_thursday(df)\n",
        "    df = filter_names(df)\n",
        "    return df\n",
        "\n",
        "# Compute total scores per program based on Big Data Brother's preferences\n",
        "def add_scores(df):\n",
        "    # Split genres string into array\n",
        "    genre_array = split(col(\"genre\"), \",\\\\s*\")\n",
        "\n",
        "    # Rule 1: +10 points if only one genre\n",
        "    one_genre_points = when(size(genre_array) == 1, 10).otherwise(0)\n",
        "\n",
        "    # Rule 2: +90 points if genre includes 'Adventure' or 'Animated'\n",
        "    has_fav_genre = when(\n",
        "        array_contains(genre_array, \"Adventure\") | array_contains(genre_array, \"Animated\"),\n",
        "        90\n",
        "    ).otherwise(0)\n",
        "\n",
        "    # Rule 3: +duration / 5\n",
        "    duration_points = col(\"Duration\") / 5\n",
        "\n",
        "    # Rule 4: +100 points if title contains 'girls' (case-insensitive)\n",
        "    girls_points = when(lower(col(\"title\")).contains(\"girls\"), 100).otherwise(0)\n",
        "\n",
        "    # Compute total score per row (airing)\n",
        "    total_score = one_genre_points + has_fav_genre + duration_points + girls_points\n",
        "\n",
        "    # Add score column to each airing\n",
        "    scored_df = df.withColumn(\"score\", total_score)\n",
        "\n",
        "    # Group by title and genre, and compute total score for each show\n",
        "    result_df = scored_df.groupBy(\"title\", \"genre\").agg(\n",
        "        _sum(\"score\").alias(\"total_score\")\n",
        "    ).orderBy(col(\"total_score\").desc())\n",
        "\n",
        "    return result_df\n"
      ],
      "metadata": {
        "id": "ih6Vx0-InwVV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Loads, cleans, filters, scores, and displays the top 20 programs based on custom rules.\n",
        "\n",
        "# Load the CSV data as a Spark DataFrame\n",
        "df = read_from_file(\"440k_data.csv\")\n",
        "\n",
        "# Convert air_date from string format 'yyyyMMdd' to Spark DateType\n",
        "df = df.withColumn(\"air_date\", to_date(col(\"air_date\"), \"yyyyMMdd\"))\n",
        "\n",
        "# Clean up Duration values:\n",
        "# - If read as strings like \"10.0\", this casts them to float first, then to int\n",
        "df = df.withColumn(\"Duration\", col(\"Duration\").cast(\"float\").cast(\"int\"))\n",
        "\n",
        "# Apply filtering:\n",
        "# - Remove shows airing on Thursday between 13:30–15:30\n",
        "# - Exclude titles containing certain unwanted keywords\n",
        "new_df = filter_df(df)\n",
        "\n",
        "# Score each viewing of remaining shows based on:\n",
        "# - Genre count\n",
        "# - Specific favorite genres\n",
        "# - Duration\n",
        "# - Title keyword (\"girls\")\n",
        "scored_df = add_scores(new_df)\n",
        "\n",
        "# Show top 20 scored programs with full row output (no truncation)\n",
        "scored_df.show(20, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQMg9h0tnTSY",
        "outputId": "a753cc8b-a980-4aed-d9bf-b655d454ec21"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+-----------------------------------------+------------------+\n",
            "|title                  |genre                                    |total_score       |\n",
            "+-----------------------+-----------------------------------------+------------------+\n",
            "|The Simpsons           |Sitcom,Animated                          |74880.4           |\n",
            "|2 Broke Girls          |Sitcom                                   |41762.6           |\n",
            "|Up to the Minute       |News                                     |23767.200000000103|\n",
            "|Futurama               |Sitcom,Science fiction,Animated          |22672.2           |\n",
            "|Mike & Molly           |Sitcom                                   |19903.799999999996|\n",
            "|The Fairly OddParents  |Children,Comedy,Animated                 |19434.0           |\n",
            "|Globe Trekker          |Travel,Adventure                         |17848.0           |\n",
            "|Modern Family          |Sitcom                                   |17040.800000000003|\n",
            "|Peppa Pig              |Children,Adventure,Entertainment,Animated|13875.000000000004|\n",
            "|Archer                 |Comedy,Animated                          |12690.999999999993|\n",
            "|NCIS: Los Angeles      |Crime drama,Action,Adventure,Mystery     |12545.599999999999|\n",
            "|Bob's Burgers          |Sitcom,Animated                          |11517.2           |\n",
            "|Robot Chicken          |Comedy,Animated                          |11442.0           |\n",
            "|Little Einsteins       |Children,Educational,Art,Music,Animated  |9881.6            |\n",
            "|Ruff-Ruff, Tweet & Dave|Children,Educational,Game show,Animated  |9645.000000000004 |\n",
            "|JAG                    |Crime drama,Action,Adventure,Law         |8772.0            |\n",
            "|Maya & Miguel          |Children,Educational,Animated            |8736.0            |\n",
            "|Rugrats                |Children,Fantasy,Animated                |8718.599999999999 |\n",
            "|Hey Arnold!            |Children,Comedy,Animated                 |8514.4            |\n",
            "|Sanjay and Craig       |Children,Adventure,Fantasy,Animated      |8241.0            |\n",
            "+-----------------------+-----------------------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}