{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10043a05-3d10-4cba-9cac-fc1f727d21bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We chose to filter out rows with missing or invalid values for key fields.\n",
    "\n",
    "This decision is based on guidance provided in the forum and the homework instructions, which state that if a row lacks the necessary information to determine viewing behavior or wealth characteristics, it can be safely disregarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba4f35d-d006-44d3-8339-fc7544c3162c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Section 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db6f7511-aa24-4446-86eb-b4450516dd0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.types import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5a2bb0ea-dbba-4278-b3d5-68bf73d95c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_csv_file(filename, schema):\n",
    "  # Reads the relevant file from distributed file system using the given schema\n",
    "\n",
    "  allowed_files = {'Daily program data': ('Daily program data', \"|\"),\n",
    "                   'demographic': ('demographic', \"|\")}\n",
    "\n",
    "  if filename not in allowed_files.keys():\n",
    "    print(f'You were trying to access unknown file \\\"{filename}\\\". Only valid options are {allowed_files.keys()}')\n",
    "    return None\n",
    "\n",
    "  filepath = allowed_files[filename][0]\n",
    "  dataPath = f\"dbfs:/mnt/coursedata2024/fwm-stb-data/{filepath}\"\n",
    "  delimiter = allowed_files[filename][1]\n",
    "\n",
    "  df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"false\")\\\n",
    "    .option(\"delimiter\",delimiter)\\\n",
    "    .schema(schema)\\\n",
    "    .load(dataPath)\n",
    "  return df\n",
    "schemas_dict = {'Daily program data':\n",
    "                  StructType([\n",
    "                    StructField('prog_code', StringType()),\n",
    "                    StructField('title', StringType()),\n",
    "                    StructField('genre', StringType()),\n",
    "                    StructField('air_date', StringType()),\n",
    "                    StructField('air_time', StringType()),\n",
    "                    StructField('Duration', FloatType())\n",
    "                  ]),\n",
    "                'viewing':\n",
    "                  StructType([\n",
    "                    StructField('device_id', StringType()),\n",
    "                    StructField('event_date', StringType()),\n",
    "                    StructField('event_time', IntegerType()),\n",
    "                    StructField('mso_code', StringType()),\n",
    "                    StructField('prog_code', StringType()),\n",
    "                    StructField('station_num', StringType())\n",
    "                  ]),\n",
    "                'viewing_full':\n",
    "                  StructType([\n",
    "                    StructField('mso_code', StringType()),\n",
    "                    StructField('device_id', StringType()),\n",
    "                    StructField('event_date', IntegerType()),\n",
    "                    StructField('event_time', IntegerType()),\n",
    "                    StructField('station_num', StringType()),\n",
    "                    StructField('prog_code', StringType())\n",
    "                  ]),\n",
    "                'demographic':\n",
    "                  StructType([StructField('household_id',StringType()),\n",
    "                    StructField('household_size',IntegerType()),\n",
    "                    StructField('num_adults',IntegerType()),\n",
    "                    StructField('num_generations',IntegerType()),\n",
    "                    StructField('adult_range',StringType()),\n",
    "                    StructField('marital_status',StringType()),\n",
    "                    StructField('race_code',StringType()),\n",
    "                    StructField('presence_children',StringType()),\n",
    "                    StructField('num_children',IntegerType()),\n",
    "                    StructField('age_children',StringType()), #format like range - 'bitwise'\n",
    "                    StructField('age_range_children',StringType()),\n",
    "                    StructField('dwelling_type',StringType()),\n",
    "                    StructField('home_owner_status',StringType()),\n",
    "                    StructField('length_residence',IntegerType()),\n",
    "                    StructField('home_market_value',StringType()),\n",
    "                    StructField('num_vehicles',IntegerType()),\n",
    "                    StructField('vehicle_make',StringType()),\n",
    "                    StructField('vehicle_model',StringType()),\n",
    "                    StructField('vehicle_year',IntegerType()),\n",
    "                    StructField('net_worth',IntegerType()),\n",
    "                    StructField('income',StringType()),\n",
    "                    StructField('gender_individual',StringType()),\n",
    "                    StructField('age_individual',IntegerType()),\n",
    "                    StructField('education_highest',StringType()),\n",
    "                    StructField('occupation_highest',StringType()),\n",
    "                    StructField('education_1',StringType()),\n",
    "                    StructField('occupation_1',StringType()),\n",
    "                    StructField('age_2',IntegerType()),\n",
    "                    StructField('education_2',StringType()),\n",
    "                    StructField('occupation_2',StringType()),\n",
    "                    StructField('age_3',IntegerType()),\n",
    "                    StructField('education_3',StringType()),\n",
    "                    StructField('occupation_3',StringType()),\n",
    "                    StructField('age_4',IntegerType()),\n",
    "                    StructField('education_4',StringType()),\n",
    "                    StructField('occupation_4',StringType()),\n",
    "                    StructField('age_5',IntegerType()),\n",
    "                    StructField('education_5',StringType()),\n",
    "                    StructField('occupation_5',StringType()),\n",
    "                    StructField('polit_party_regist',StringType()),\n",
    "                    StructField('polit_party_input',StringType()),\n",
    "                    StructField('household_clusters',StringType()),\n",
    "                    StructField('insurance_groups',StringType()),\n",
    "                    StructField('financial_groups',StringType()),\n",
    "                    StructField('green_living',StringType())\n",
    "                  ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a819f373-58aa-4987-80b7-9601edfd3754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets using pre-defined schema and helper\n",
    "program_df = load_csv_file('Daily program data', schemas_dict['Daily program data'])\n",
    "demographic_df = load_csv_file('demographic', schemas_dict['demographic'])\n",
    "\n",
    "# Load reference data (parquet)\n",
    "ref_data_schema = StructType([\n",
    "    StructField('device_id', StringType()),\n",
    "    StructField('dma', StringType()),\n",
    "    StructField('dma_code', StringType()),\n",
    "    StructField('household_id', IntegerType()),\n",
    "    StructField('zipcode', IntegerType())\n",
    "])\n",
    "reference_df = spark.read.format('parquet') \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"dbfs:/FileStore/ddm/ref_data\")\n",
    "\n",
    "# Load viewing data (CSV with schema)\n",
    "viewing_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .schema(schemas_dict['viewing_full']) \\\n",
    "    .load(\"dbfs:/FileStore/ddm/10m_viewing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "194a4b20-3431-4559-8cd8-551ce106de42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "program_df = program_df.dropDuplicates()\n",
    "demographic_df = demographic_df.dropDuplicates()\n",
    "reference_df = reference_df.dropDuplicates()\n",
    "viewing_df = viewing_df.dropDuplicates()\n",
    "\n",
    "\n",
    "program_df = program_df.cache()\n",
    "demographic_df = demographic_df.cache()\n",
    "reference_df = reference_df.cache()\n",
    "viewing_df = viewing_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8c2b404c-9d6f-47da-b958-ab3f34481f49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast key columns to correct types and compute new ones:\n",
    "# - program_df: duration (int), air_date (date), air_time (int)\n",
    "# - viewing_df: event_date (date), event_time (int)\n",
    "# - reference_df: household_id as 8-digit string\n",
    "# - demographic_df:\n",
    "#     - income_num: maps income brackets (A–D) or integers to numerical scale\n",
    "#     - num_adults, age_individual, age_2 cast to int\n",
    "\n",
    "program_df = program_df.withColumn(\"duration\", col(\"duration\").cast(\"int\")) \\\n",
    "                       .withColumn(\"air_date\", to_date(col(\"air_date\"), \"yyyyMMdd\")) \\\n",
    "                       .withColumn(\"air_time\", col(\"air_time\").cast(\"int\"))\n",
    "\n",
    "viewing_df = viewing_df.withColumn(\"event_date\", to_date(col(\"event_date\"), \"yyyyMMdd\")) \\\n",
    "                       .withColumn(\"event_time\", col(\"event_time\").cast(\"int\"))\n",
    "\n",
    "\n",
    "reference_df = reference_df.withColumn( \"household_id\",\n",
    "    lpad(col(\"household_id\").cast(\"string\"), 8, \"0\")  # Pad with zeros to 8 characters\n",
    ")\n",
    "\n",
    "\n",
    "demographic_df = demographic_df.withColumn(\"num_adults\", col(\"num_adults\").cast(\"int\")) \\\n",
    "    .withColumn(\"income\", \n",
    "                when(col(\"income\").rlike(\"^[A-D]$\"), ascii(substring(\"income\", 1, 1)) - ascii(lit(\"A\")) + 10)\n",
    "                .otherwise(col(\"income\").cast(\"int\"))\n",
    "    ) \\\n",
    "    .withColumn(\"age_individual\", col(\"age_individual\").cast(\"int\")) \\\n",
    "    .withColumn(\"age_2\", col(\"age_2\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ecef06b9-835c-4863-81cd-57981eabba88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Trim program_df to required columns\n",
    "program_df = program_df.select(\"prog_code\", \"title\", \"genre\", \"air_date\", \"air_time\", \"duration\")\n",
    "\n",
    "# 2. Trim demographic_df to columns needed for conditions 2, 3, and 5\n",
    "demographic_df = demographic_df.select(\n",
    "    \"household_id\", \"num_adults\", \"age_individual\", \"age_2\", \"num_vehicles\", \"vehicle_make\", \"income\"\n",
    ")\n",
    "\n",
    "# 3. Trim reference_df to device-household mapping\n",
    "reference_df = reference_df.select(\"device_id\", \"household_id\")\n",
    "\n",
    "# 4. Trim viewing_df to viewing info only\n",
    "viewing_df = viewing_df.select(\"device_id\", \"prog_code\", \"event_date\", \"event_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c2fa00ac-c9aa-4670-9e7d-451602e1c52b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---- Program-level conditions ----\n",
    "avg_duration = program_df.select(avg(\"duration\")).first()[0]\n",
    "\n",
    "program_df = program_df.withColumn(\"cond_1\", col(\"duration\") > avg_duration)\n",
    "\n",
    "program_df = program_df.withColumn(\n",
    "    \"cond_4\",\n",
    "    (dayofmonth(col(\"air_date\")) == 13) & (dayofweek(col(\"air_date\")) == 6)\n",
    ")\n",
    "\n",
    "program_df = program_df.withColumn(\"cond_6\",\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Collectibles\") |\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Art\") |\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Snowmobile\") |\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Public affairs\") |\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Animated\") |\n",
    "    array_contains(split(col(\"genre\"), \",\\\\s*\"), \"Music\")\n",
    ")\n",
    "\n",
    "# Title match on >=2 of: 'better', 'girls', 'the', 'call'\n",
    "title_words = [\"better\", \"girls\", \"the\", \"call\"]\n",
    "program_df = program_df.withColumn(\"cond_7\", \n",
    "    (size(\n",
    "        expr(f\"\"\"filter(array({','.join([f\"lower(title) like '%{w}%'\" for w in title_words])}), x -> x)\"\"\")\n",
    "    ) >= 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270f5c7a-e207-45e2-90a5-82203915aa9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---- Demographic-based conditions via viewings ----\n",
    "\n",
    "device_counts_df = reference_df.groupBy(\"household_id\") \\\n",
    "    .agg(countDistinct(\"device_id\").alias(\"device_count\"))\n",
    "\n",
    "demographic_df = demographic_df.join(device_counts_df, on=\"household_id\", how=\"left\")\n",
    "\n",
    "# 1. Compute conditions in demographic_df\n",
    "mean_income = demographic_df.select(avg(\"income\")).first()[0]\n",
    "\n",
    "demographic_df = demographic_df.withColumn(\"cond_2\", col(\"vehicle_make\") == \"91\") \\\n",
    "    .withColumn(\"cond_3\", (col(\"num_adults\") == 2) & (abs(col(\"age_individual\") - col(\"age_2\")) <= 6)) \\\n",
    "    .withColumn(\"cond_5\", (col(\"device_count\") > 3) & (col(\"income\") < mean_income))\n",
    "\n",
    "# 2. Join device conditions\n",
    "device_conditions_df = reference_df.join(demographic_df, on=\"household_id\", how=\"inner\") \\\n",
    "                                   .select(\"device_id\", \"cond_2\", \"cond_3\", \"cond_5\")\n",
    "\n",
    "# 3. Link viewings to program codes and devices\n",
    "viewing_conditions_df = viewing_df.select(\"prog_code\", \"device_id\").distinct() \\\n",
    "                                  .join(device_conditions_df, on=\"device_id\", how=\"inner\")\n",
    "\n",
    "# 4. Aggregate to get whether any viewing of a program satisfied each condition\n",
    "from pyspark.sql.functions import max as spark_max\n",
    "\n",
    "prog_demo_conditions_df = viewing_conditions_df.groupBy(\"prog_code\").agg(\n",
    "    spark_max(col(\"cond_2\").cast(\"int\")).alias(\"cond_2\"),\n",
    "    spark_max(col(\"cond_3\").cast(\"int\")).alias(\"cond_3\"),\n",
    "    spark_max(col(\"cond_5\").cast(\"int\")).alias(\"cond_5\")\n",
    ")\n",
    "\n",
    "# 5. Join onto program_df\n",
    "program_df = program_df.join(prog_demo_conditions_df, on=\"prog_code\", how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580a803b-ed1d-4401-94a5-f3ac05f5982f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Section 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed633db4-8928-413e-bf89-f5cedad6419c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_cond_cols = [f\"cond_{i}\" for i in range(1, 8)]\n",
    "\n",
    "program_df = program_df.withColumn(\n",
    "    \"cond_count\",\n",
    "    reduce(lambda a, b: a + b, (col(c).cast(\"int\") for c in all_cond_cols))\n",
    ").drop(*all_cond_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebdd3c0-f068-4d74-bac6-53f09721acb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[title: string, malicious_ratio: double]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Flag program airings that meet at least 4 of the 7 conditions\n",
    "program_df = program_df.withColumn(\"is_malicious\", col(\"cond_count\") >= 4)\n",
    "\n",
    "# Step 2: Count total and malicious records per title\n",
    "malicious_stats_df = program_df.groupBy(\"title\").agg(\n",
    "    count(\"*\").alias(\"total_records\"),\n",
    "    sum(when(col(\"is_malicious\"), 1).otherwise(0)).alias(\"malicious_records\")\n",
    ")\n",
    "\n",
    "# Step 3: Compute malicious percentage\n",
    "malicious_stats_df = malicious_stats_df.withColumn(\n",
    "    \"malicious_ratio\", col(\"malicious_records\") / col(\"total_records\")\n",
    ")\n",
    "\n",
    "# Step 4: Filter to titles with >40% malicious and get top 20 by malicious percentage\n",
    "top_malicious_titles = (\n",
    "    malicious_stats_df\n",
    "    .filter(col(\"malicious_ratio\") > 0.4)\n",
    "    .orderBy(col(\"malicious_ratio\").desc())\n",
    ").select(\"title\", \"malicious_ratio\")\n",
    "top_malicious_titles.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4514bad8-381d-401d-ac07-1cf41a1de09a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>malicious_ratio</th></tr></thead><tbody><tr><td>Poseidon</td><td>1.0</td></tr><tr><td>Notes From the Heart Healer</td><td>1.0</td></tr><tr><td>Local 24 News Good Day 6am</td><td>1.0</td></tr><tr><td>Concorde: Flying Supersonic</td><td>1.0</td></tr><tr><td>12 O'Clock Boys</td><td>1.0</td></tr><tr><td>Good Day Atlanta 7:00am</td><td>1.0</td></tr><tr><td>Failure to Launch</td><td>1.0</td></tr><tr><td>Songs That Don't Suck</td><td>1.0</td></tr><tr><td>MC Alternative</td><td>1.0</td></tr><tr><td>Jamie Marks Is Dead</td><td>1.0</td></tr><tr><td>Encino Man</td><td>1.0</td></tr><tr><td>Rebelde</td><td>1.0</td></tr><tr><td>Richard Pryor: Omit the Logic</td><td>1.0</td></tr><tr><td>WWE Raw En Español</td><td>1.0</td></tr><tr><td>Seven Psychopaths</td><td>1.0</td></tr><tr><td>A Toda Gloria</td><td>1.0</td></tr><tr><td>Mornin'</td><td>1.0</td></tr><tr><td>Exploring With the Scholars</td><td>1.0</td></tr><tr><td>Good Day Oregon at 6am</td><td>1.0</td></tr><tr><td>Fox34 Weather Nation</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Poseidon",
         1.0
        ],
        [
         "Notes From the Heart Healer",
         1.0
        ],
        [
         "Local 24 News Good Day 6am",
         1.0
        ],
        [
         "Concorde: Flying Supersonic",
         1.0
        ],
        [
         "12 O'Clock Boys",
         1.0
        ],
        [
         "Good Day Atlanta 7:00am",
         1.0
        ],
        [
         "Failure to Launch",
         1.0
        ],
        [
         "Songs That Don't Suck",
         1.0
        ],
        [
         "MC Alternative",
         1.0
        ],
        [
         "Jamie Marks Is Dead",
         1.0
        ],
        [
         "Encino Man",
         1.0
        ],
        [
         "Rebelde",
         1.0
        ],
        [
         "Richard Pryor: Omit the Logic",
         1.0
        ],
        [
         "WWE Raw En Español",
         1.0
        ],
        [
         "Seven Psychopaths",
         1.0
        ],
        [
         "A Toda Gloria",
         1.0
        ],
        [
         "Mornin'",
         1.0
        ],
        [
         "Exploring With the Scholars",
         1.0
        ],
        [
         "Good Day Oregon at 6am",
         1.0
        ],
        [
         "Fox34 Weather Nation",
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "malicious_ratio",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(top_malicious_titles.limit(20))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "project1_part1_212536924_322836180",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}